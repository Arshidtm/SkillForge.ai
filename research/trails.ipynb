{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "welcome\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('welcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv('RAPIDAPI_KEY')\n",
    "\n",
    "INDIAN_CITIES = [\n",
    "    \"Mumbai\", \"Delhi\", \"Bangalore\", \"Hyderabad\", \"Ahmedabad\",\n",
    "    \"Chennai\", \"Kolkata\", \"Surat\", \"Pune\", \"Jaipur\",\n",
    "    \"Lucknow\", \"Kanpur\", \"Nagpur\", \"Visakhapatnam\", \"Indore\",\n",
    "    \"Thane\", \"Bhopal\", \"Patna\", \"Vadodara\", \"Ghaziabad\"\n",
    "]\n",
    "\n",
    "def fetch_jobs(query, location=\"India\", results_wanted=5,api_key=api_key):\n",
    "    conn = http.client.HTTPSConnection(\"jobs-search-api.p.rapidapi.com\")\n",
    "    \n",
    "    # If location is \"India\", use random cities\n",
    "    if location.lower() == \"india\":\n",
    "        # Calculate how many jobs per city (at least 1 city per job)\n",
    "        jobs_per_city = max(1, results_wanted // len(INDIAN_CITIES))\n",
    "        all_jobs = []\n",
    "        \n",
    "        for city in random.sample(INDIAN_CITIES, min(len(INDIAN_CITIES), results_wanted)):\n",
    "            payload = json.dumps({\n",
    "                \"search_term\": query,\n",
    "                \"location\": f\"{city}, India\",\n",
    "                \"results_wanted\": jobs_per_city,\n",
    "                \"site_name\": [\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "                \"distance\": 50,\n",
    "                \"job_type\": \"fulltime\",\n",
    "                \"is_remote\": False,\n",
    "                \"linkedin_fetch_description\": True,\n",
    "                \"hours_old\": 72\n",
    "            })\n",
    "\n",
    "            headers = {\n",
    "\t'x-rapidapi-key': api_key,\n",
    "    'x-rapidapi-host': \"jobs-search-api.p.rapidapi.com\",\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "\n",
    "            try:\n",
    "                conn.request(\"POST\", \"/getjobs\", body=payload, headers=headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                city_jobs = json.loads(data).get(\"jobs\", [])\n",
    "                \n",
    "                # Add city information to each job\n",
    "                for job in city_jobs:\n",
    "                    job[\"searched_location\"] = city\n",
    "                all_jobs.extend(city_jobs)\n",
    "                \n",
    "                # Stop if we've collected enough jobs\n",
    "                if len(all_jobs) >= results_wanted:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching jobs for {city}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        # Trim to exact result count and format\n",
    "        return [\n",
    "            {\n",
    "                \"job title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"location\": job.get(\"location\", \"N/A\"),\n",
    "                \"searched_city\": job.get(\"searched_location\", \"India\"),\n",
    "                \"description\": job[\"description\"]\n",
    "            }\n",
    "            for job in all_jobs[:results_wanted]\n",
    "            if all(key in job for key in [\"title\", \"company\", \"description\"])\n",
    "        ]\n",
    "    \n",
    "    else:\n",
    "        # Original single-location logic\n",
    "        payload = json.dumps({\n",
    "            \"search_term\": query,\n",
    "            \"location\": location,\n",
    "            \"results_wanted\": results_wanted,\n",
    "            \"site_name\": [\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "            \"distance\": 50,\n",
    "            \"job_type\": \"fulltime\",\n",
    "            \"is_remote\": False,\n",
    "            \"linkedin_fetch_description\": True,\n",
    "            \"hours_old\": 72,\n",
    "            \"show_requirements\": True, \n",
    "        })\n",
    "\n",
    "        headers = {\n",
    "\t'x-rapidapi-key': api_key,\n",
    "    'x-rapidapi-host': \"jobs-search-api.p.rapidapi.com\",\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "\n",
    "        conn.request(\"POST\", \"/getjobs\", body=payload, headers=headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read().decode(\"utf-8\")\n",
    "        job_data = json.loads(data)\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"job title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"location\": job.get(\"location\", \"N/A\"),\n",
    "                \"searched_city\": location.split(\",\")[0].strip(),\n",
    "                \"description\": job[\"description\"]\n",
    "            }\n",
    "            for job in job_data.get(\"jobs\", [])\n",
    "            if all(key in job for key in [\"title\", \"company\", \"description\"])\n",
    "        ]\n",
    "        \n",
    "def clean_text(text):\n",
    "    \"\"\"Remove excessive newlines and markdown bold syntax\"\"\"\n",
    "    text = re.sub(r'\\*\\*', '', text)  # Remove **bold** markers\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)  # Replace 3+ newlines with double newlines\n",
    "    return text.strip()\n",
    "\n",
    "def documentation(job_details):\n",
    "    content=[] \n",
    "    for job in job_details: \n",
    "        doc = Document(\n",
    "                page_content=clean_text(job[\"description\"]),\n",
    "                metadata={\n",
    "                    \"job_title\": job[\"job title\"],\n",
    "                    \"company\": job[\"company\"],\n",
    "                    \"location\": job[\"location\"],\n",
    "                    \"searched_city\": job[\"searched_city\"],\n",
    "                    \n",
    "                    \"language\": \"en\"\n",
    "                    }\n",
    "                )\n",
    "        content.append(doc)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs='Data Science'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_jobs=fetch_jobs(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job title': 'Consultant (Credit Risk Modelling), Data Science & Analytics',\n",
       "  'company': 'TransUnion',\n",
       "  'location': 'Pune',\n",
       "  'searched_city': 'Pune',\n",
       "  'description': 'TransUnion\\'s Job Applicant Privacy Notice\\n\\n\\n**What We\\'ll Bring:**\\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n**What You\\'ll Bring:**\\n\\nWhat we’ll bring:\\n  \\n\\n* A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.\\n* Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.\\n* Our culture encourages our people to hone current skills and build new capabilities while discovering their genius.\\n* We provide a modern computing environment based on best\\\\-in\\\\-class \"big data\" and cloud computing technologies and the freedom to explore new data sources and statistical and machine learning methodologies.\\n* Our Analytics team is home to some of the most brilliant minds in the market. Here, we will not only understand your stats jokes, we’ll appreciate them.\\n\\n  \\n\\nWhat you’ll bring:\\n  \\n\\n* Bachelors (4 year) degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least four (6\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Strong analytical, critical thinking, and creative problem\\\\-solving skills\\n* Excellent understanding of machine learning techniques and algorithms, such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, Gradient Boosting, etc.\\n* Advanced programming skills; proficiency with a statistical language such as R; experience using other programming and data manipulation languages preferred (SQL, Hive, Pig, Python, C/C\\\\+\\\\+, Java); high level of familiarity with Microsoft Office tools\\n* Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast\\\\-paced environment\\n* Strong project management skills with the ability to manage multiple assignments effectively\\n* Ability to travel 10\\\\-20%\\n\\n  \\n\\nWhat we\\'d prefer to see:\\n  \\n\\n* Master’s (2 years) or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least one (1\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Familiarity with credit bureau data and business practices\\n* Experienced with Tableau or other visualization tools\\n* Advanced skills using Excel formulas, macros, and pivot tables to provide detailed analytical reports.\\n* Operates under modest supervision in a complex and dynamic, matrixed environment\\n* Experienced working in a company with a global presence\\n* Experience with modern \"big data\" frameworks (Hadoop, Spark, cloud)\\n\\n  \\n\\n  \\n\\nImpact you’ll make:\\n  \\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n  \\n\\n  \\n\\n* You will partner with internal and external cross\\\\-functional teams to drive new business initiatives and deliver long term value\\\\-added product propositions for TU’s B2B customers globally. This includes but is not limited to developing predictive risk management and business intelligence solutions for credit card issuers, auto \\\\& mortgage lenders, collections agencies, and retail banks.\\n* You will contribute in analytic engagements involving descriptive, predictive, and prescriptive analysis through the consumer lending portfolio lifecycle, leveraging various techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).\\n* You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, Python, SQL, Hive, and Spark on server and cloud based computing platforms.\\n* You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.\\n* You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.\\n* You will foster a high performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.\\n**Impact You\\'ll Make:**\\n\\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\\n\\n\\nThis is a hybrid position and involves regular performance of job responsibilities virtually as well as in\\\\-person at an assigned TU office location for a minimum of two days a week.\\nTransUnion Job Title\\n\\n\\nConsultant, Data Science and Analytics'},\n",
       " {'job title': 'Data Scientist',\n",
       "  'company': 'LTIMindtree',\n",
       "  'location': 'Pune, Maharashtra, India',\n",
       "  'searched_city': 'Pune',\n",
       "  'description': 'LTIMindtree is looking for Data Scientist Role\\n \\n\\n\\n\\n Experience\\\\- 5 to 8 Years\\n \\n\\n\\n\\n Job Location\\\\- Pune\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n Data Scientist\\n \\n\\n\\n\\n Strong problemsolving skills and ability to deliver highquality datafocused solutions\\n \\n\\n\\n\\n Proficiency in Python SQL and expertise in machine learning and deep learning algorithms\\n \\n\\n\\n\\n Experience with generative AI and LangChain for building and deploying advanced models\\n \\n\\n\\n\\n Proficiency in Azure cloud services for implementing and managing AI solutions\\n \\n\\n\\n\\n Drive the development of impactful data products to support business objectives\\n \\n\\n\\n\\n\\n\\n\\n\\n Skills\\\\-Machine Learning, Deep Learing, Python, Pytorch, Cloud,AI, Gen AI exp mandatory\\n \\n\\n\\n\\n If interested please share below details on darshana.potdukhe@ltimindtree.com\\n \\n\\n\\n\\n Total Experience:\\n \\n\\n\\n\\n Current CTC:\\n \\n\\n\\n\\n Expected CTC:\\n \\n\\n\\n\\n Official NP: (If serving last working day)'},\n",
       " {'job title': 'Data Analyst',\n",
       "  'company': 'Jaipur Rugs',\n",
       "  'location': 'Jaipur, Rajasthan, India',\n",
       "  'searched_city': 'Jaipur',\n",
       "  'description': \"**Job brief** \\n\\n\\n\\n\\n We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n As the Lead \\\\- Analytics, you will lead our strategic efforts to leverage data in alignment with our business objectives. Your role will be pivotal in fostering a culture of analytics, implementing best practices, and improving data\\\\-driven decision making. You will align and direct the development, management, and integration of our analytics and business intelligence (BI) capability to support the mission, vision, objectives, and goals of the overall business. Additionally, we seek someone who comprehensively understands how the business operates as a whole, recognizing the importance of analytics in each department to paint a cohesive and comprehensive picture.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Essential Responsibilities:** \\n\\n\\n\\n\\n • Strategic Leadership: Drive a culture of Business Intelligence by assisting in architecting and executing a visionary analytics strategy that harnesses our data ecosystem. Responsible for driving departmental adoption of analytics while promoting data\\\\-driven decision\\\\-making and customer\\\\- and consumer\\\\-driven insights.\\n \\n\\n\\n\\n • Excellent Communication \\\\& Coordination: Since the position will primarily be coordinating \\\\& working with our U.S office team, hence excellent command over verbal \\\\& written English is an important pre\\\\-requisite for the position. Ideal candidate should be open for working as per US shift timings.\\n \\n\\n\\n\\n • Analytics Infrastructure: Collaborate with IT Architecture Leadership around the development and maintenance of robust analytics infrastructure, including data warehouses, reporting tools, and visualization platforms.\\n \\n\\n\\n\\n • Analytics and Modeling: Establish a foundation for deploying advanced statistical models and machine learning algorithms in the future, focusing on building the necessary infrastructure and expertise for predictive analysis and optimization.\\n \\n\\n\\n\\n • Dashboard and KPI Management: Develop dashboards and KPIs to drive decision\\x02making processes.\\n \\n\\n\\n\\n • Collaboration and Influence: Collaborate with key stakeholders across departments to understand business needs and translate them into data and analytics requirements. Act as a bridge between technical teams and business units, translating complex data insights into actionable business strategies. Effective communication with both technical and non\\\\-technical team members.\\n \\n\\n\\n\\n • Legacy: Comfortable with creating foundational data strategy that will enable a hyper growth strategy.\\n \\n\\n\\n\\n • Data Governance: Ensure data integrity and consistency across all reporting, documentation of data assets and KPIs, establish source of truth for data domains. Implement data quality standards and procedures, overseeing data cleansing and validation processes.\\n \\n\\n\\n\\n • Technical Expertise: Utilize SSIS for ETL processes, ensuring seamless data integration and automation across systems. Employ Power BI for comprehensive business intelligence solutions, creating dynamic reports and dashboards that drive decision\\\\-making\\n \\n\\n\\n\\n • Continuous Improvement: Stay informed about industry trends and emerging technologies in data and analytics. Identify opportunities for process optimization and the application of advanced analytics techniques and build a 3\\\\-year roadmap for data analytics.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Skills \\\\& Minimum Qualifications:** \\n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of knowledge, skill, and/or ability required. Reasonable accommodation may be made to enable individuals with disabilities to perform essential functions.\\n \\n\\n\\n\\n • Bachelors or Master's in Data Science, Computer Science, or related fields. • At least 7 years of experience in a leadership role within analytics/data science, specifically within the retail or ecommerce sector.\\n \\n\\n\\n\\n • Working knowledge in data management and analytics platforms, such as SQL Server, SSIS, Power BI, and Google Analytics. • Demonstrated ability in statistical analysis, predictive modeling, and machine learning techniques.\\n \\n\\n\\n\\n • Demonstrated ability to analyze and interpret trends in large datasets, identifying patterns and insights that drive strategic decision\\\\-making.\\n \\n\\n\\n\\n • Familiarity with ERP systems and their application in data\\\\-driven business environments.\\n \\n\\n\\n\\n • Experience in implementing tailored solutions to improve customer journey mapping, satisfaction metrics, and brand loyalty.\\n \\n\\n\\n\\n • Proficiency in warehouse management tools, demonstrating expertise in utilizing data analytics to optimize supply chain operations and enhance efficiency within warehouse management systems.\\n \\n\\n\\n\\n • Ability to communicate trends and their implications clearly and concisely to stakeholders at all levels of the organization, informing strategic planning and resource allocation.\\n \\n\\n\\n\\n • Strong project management skills, presentation skills, and a successful track record of leading successful cross\\\\-functional initiatives.\\n \\n\\n\\n\\n • Demonstrated track record of working with consumer brand initiatives or enhancing customer experiences through data\\\\-driven strategies.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Specialized Training or Knowledge:** \\n\\n\\n\\n\\n • Proficiency with Microsoft Office applications, with expertise in Excel (e.g., pivot tables, advanced functions, formulas, filtering, etc.) and database skills (e.g., SQL)\\n \\n\\n\\n\\n • Ability to collect and synthesize information, making it relevant, understandable, and actionable for key stakeholders\\n \\n\\n\\n\\n • Ability to balance multiple projects with competing deadlines\\n \\n\\n\\n\\n • Generate insights that improve the business through linking various data sources\\n \\n\\n\\n\\n • Strong understanding of Analytics and Visualization techniques\"},\n",
       " {'job title': 'iOS Team Lead',\n",
       "  'company': 'Optimumbrew Technology',\n",
       "  'location': 'India',\n",
       "  'searched_city': 'Surat',\n",
       "  'description': '**We are looking for talented iOS Team Leader who are passionate and know\\\\-how the process of building scalable and secure functionality on top of the iOS platform. You will be associated with a qualified and experienced pool of people with whom you will build correlations by sharing your experience and growing your capabilities.**\\n\\n**Primary Objectives**\\n\\n* Experience in leading a small group of team members.\\n* Professional experience with swift code for iOS.\\n* Practical experience in applying OOPs techniques and design patterns in everyday coding.\\n* Expertise of iOS SDK, different versions of iOS, and how to deal with different screen sizes.\\n* Experience working with remote data via REST API and JSON.\\n* Proper knowledge of the iOS development life cycle.\\n* Understanding of iOS App Code signing process and deployment process.\\n* Ability to understand business requirements and translate them into technical requirements.\\n* Experience with offline storage, threading, and performance tuning.\\n* Experience with development in third\\\\-party libraries, and APIs.The desire to be continually learning about newly emerging technologies/industry\\n* trends \\\\& challenges, perform duties with minimal guidance.\\n* Solid hands\\\\-on experience in developing native iOS apps.\\n* Hands\\\\-on experience in Cloud APIs, push notifications, Social sign\\\\-in, Crashlytics,\\n* integration of analytics is an added advantage.\\n* Proficient understanding of code versioning tools, such as Git, SVN.\\n* Experience with performance and memory tuning with tools.\\n* Proven leadership skills, including the ability to motivate and lead other talented developers.\\n* Ability to take a project from scoping requirements through launch.\\n* Experience in dealing with multiple projects.\\n* Understanding and familiarity with common code review methods and standards.\\n* Experience building and delivering highly scalable, reliable, and complex software\\n* systems on – time and on budget.\\n* Should be ready to learn new things and take challenges.\\n\\n**Roles \\\\& Responsibilities**\\n\\n* Bring your own unique expertise to the team and learn from others.\\n* Take ownership, be creative, and think outside the box to invent and build solutions\\n* to real\\\\-world customer problems.\\n* Providing technical leadership and guidance on project plans and delivery commitments.\\n* Manage the day\\\\-to\\\\-day activities of an engineering team. Project planning,\\n* milestones/deadlines date definition, task estimation, scope of work assessment, etc.\\n* Participating in the recruitment process, providing input for performance appraisals.\\n* Manage individual team members, both junior and senior, encouraging their\\n* professional growth and maximizing their potential contributions. Lead in Architecting and developing new features in accordance with our product roadmap.\\n* Accountable for the team’s performance, work satisfaction, and growth.\\n* Provide thought leadership on industry best practices around design, testing, and security.\\n* Design and build advanced applications for the iOS platform.\\n* Creating app updates, including bug fixes and additional features, for release.\\n* Collaborating with UI and UX Designers, as well as Software Testers, to ensure that\\n* each app is presentable and in perfect working order.\\n* Proofreading code and correcting mistakes before each app is released.\\n* Ensure the best possible performance, quality, and responsiveness of the application.\\n* Strictly follow instructions \\\\& guidelines given by a project manager.\\n* Help maintain code quality, organization and automation.\\n* Fully responsible for mobile app development in the team.\\n* Work on improving application performance.\\n* Monitoring app reviews to detect areas for improvement.\\n* Continuously discover new ways to implement new technologies to improve\\n* development efficiency.\\n* Help your team solve problems in a way that makes sense for iOS users and our codebase.\\n* Join other developers and help to shape the direction of Android development at our company.\\n* Insist on a consistent and responsive user experience for every one of our users.\\n* Design, build, and maintain high performance, reusable, and reliable swift code.\\n* Give training to Jr. \\\\& fresher developers.\\n* Continuous Integration, and strategy, planning and execution.\\n* Manage individual team members, both junior and senior, encouraging their professional growth and maximizing their potential contributions.\\n* Accountable for the team’s performance, work satisfaction and growth.\\n* Establish ways for team members to complete their tasks.\\n* Define milestones for a new project.\\n* Assign targets to the team, and ensure that the targets are met.\\n* Suggest new things \\\\& methods of work to the team as \\\\& when required.\\n* Check the status of assigned tasks daily and resolve issues the team members face.\\n\\n**Technical Skills You Should Have**\\n\\n* Positive thinking and motivator for other team members.\\n* Great team player who works well in collaborative situations.\\n* A breadth of technical skills and know how to use the right tool for the job.\\n* A positive can\\\\-do attitude and bring a passion for excellence to the workplace.\\n* Translate designs and wireframes into high quality code.\\n* Excellent understanding of Swift, Xcode, Core Data, Auto Layout, Git, iOS Human\\n* Interface Guidelines, REST APIs and JSON.\\n* Understand business requirements and translate them into technical requirements.\\n* Excellent coding and proofreading skills.\\n* Passionate about creating great code.\\n* Complex problem solving and ability to multitask.\\n* Top\\\\-notch teamwork and communication skills.\\n* Creativity and brainstorming.\\n* Unwavering curiosity.\\n* Familiarity with continuous integration.\\n* Eagerness to embrace scalability, reliability, and performance challenges.\\n* Excellent verbal \\\\& written communication skills.\\n* Good interpersonal and decision making skills.\\n* Building Relationship with team members.\\n* A passion for technology and the ability to learn new concepts quickly.\\n* A systematic and quality\\\\-oriented way of working.\\n* Experience with task planning and estimating effort.\\n* Approach to tackle technical challenges with an open mind and desire to innovate.\\n\\n**Key Expertise**\\n\\n* Swift, Xcode, Core Data, Auto Layout, Git, iOS Human\\n* Interface Guidelines, REST APIs and JSON.\\n\\n**Qualification**\\n\\n* Bachelor’s Degree in Computer Science or Computer Engineering,\\n* B.Tech (CSE/ IT), M.Tech (CSE/IT), B.E. (CE/IT), M.E.(CE/IT)\\n\\n**Experience**\\n\\n* 4\\\\+ years of experience in iOS Team Leader\\n\\n**Benefits**\\n\\n* 22 Paid Leaves\\n* 5 Days Working\\n* Good Company Culture\\n* Health Insurance\\n* Pension Scheme\\n* Statutory Benefits (PF \\\\& ESIC)\\n* Salary on time\\n* Yearly Picnic\\n* Annual Sports Day\\n* Monthly Events\\n* Festival Celebrations\\n\\nJob Type: Full\\\\-time\\n\\nPay: Up to ₹1,200,000\\\\.00 per year\\n\\nSchedule:\\n\\n* Day shift\\n* Monday to Friday\\n\\nSupplemental Pay:\\n\\n* Performance bonus\\n\\nWork Location: In person'},\n",
       " {'job title': 'AI/ML Developer',\n",
       "  'company': 'WebOsmotic Private Limited',\n",
       "  'location': 'Surat, Gujarat, India',\n",
       "  'searched_city': 'Surat',\n",
       "  'description': 'We are seeking a skilled AI Developer with at least 2 years of experience in AI, Machine Learning (ML), Deep Learning (DL), and Computer Vision. The ideal candidate will have a strong foundation in:\\n \\n\\n\\n* Large Language Models (LLM)\\n* Retrieval\\\\-Augmented Generation (RAG) frameworks\\n* Developing, fine\\\\-tuning, and optimizing AI models\\n* Computer Vision techniques and their applications\\n\\n\\n\\n Proficiency in\\xa0\\n **Python programming** \\n \\xa0and experience in building and deploying scalable\\xa0\\n **REST APIs** \\n \\xa0(using frameworks such as Flask, FastAPI, Django) is essential.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**No. of Vacancies:** \\n \\xa03\\n \\n\\n\\n\\n**Qualification:** \\n\\n\\n\\n* Bachelor’s degree in Computer Science, IT, or a related field.\\n* 2\\\\+ years of proven experience in AI/ML development and Python programming.\\n* Proficiency in\\xa0\\n **Machine Learning, Deep Learning, and Artificial Intelligence** \\n \\xa0concepts.\\n* Strong portfolio showcasing AI/ML projects and achievements.\\n\\n\\n AI/ML Developer\\n \\n**Role \\\\& Responsibilities:** \\n\\n\\n\\n* Develop, fine\\\\-tune, and optimize\\xa0\\n **Large Language Models (LLMs)** \\n \\xa0and\\xa0\\n **Deep Learning models** \\n \\xa0for AI and Computer Vision applications.\\n* Implement and optimize\\xa0\\n **Retrieval\\\\-Augmented Generation (RAG)** \\n \\xa0frameworks to enhance AI model performance.\\n* Apply\\xa0\\n **agentic LLM frameworks** \\n \\xa0to build autonomous AI agents for real\\\\-world use cases.\\n* Develop\\xa0\\n **computer vision models** \\n \\xa0for tasks such as\\xa0\\n **image recognition, object detection, segmentation, and video analysis** \\n .\\n* Integrate AI and Computer Vision models into production systems through\\xa0\\n **REST APIs** \\n \\xa0and backend frameworks (\\n **Flask, FastAPI, Django** \\n ).\\n* Collaborate with cross\\\\-functional teams to design, test, and deploy AI solutions.\\n* Regularly evaluate AI models and conduct\\xa0\\n **performance optimizations** \\n \\xa0to ensure robustness and scalability.\\n* Stay updated on the latest advancements in\\xa0\\n **AI, ML, DL, and Computer Vision** \\n .\\n\\n\\n\\n \\xa0\\n \\n\\n\\n\\n**Required Skills:** \\n\\n\\n\\n* 2\\\\+ years of professional experience in\\xa0\\n **AI/ML development** \\n , with a focus on\\xa0\\n **ML, DL, and Computer Vision** \\n .\\n* Experience with\\xa0\\n **Large Language Models (LLM)** \\n \\xa0and\\xa0\\n **Retrieval\\\\-Augmented Generation (RAG) frameworks** \\n .\\n* Proficiency in\\xa0\\n **Python programming** \\n \\xa0and hands\\\\-on experience with ML/DL libraries such as\\xa0\\n **TensorFlow, PyTorch, OpenCV, etc.**\\n* Experience in designing, training, and optimizing\\xa0\\n **machine learning and deep learning models** \\n , including\\xa0\\n **computer vision tasks** \\n .\\n* Knowledge of\\xa0\\n **agentic LLM frameworks** \\n \\xa0(e.g.,\\xa0\\n **LangChain, GPT\\\\-Agents** \\n ).\\n* Strong experience in\\xa0\\n **building and deploying REST APIs** \\n \\xa0using\\xa0\\n **Flask, FastAPI, or Django** \\n .\\n* Solid understanding of\\xa0\\n **computer vision techniques** \\n \\xa0(image recognition, object detection, segmentation).\\n* Strong\\xa0\\n **problem\\\\-solving skills** \\n \\xa0with the ability to work independently in a fast\\\\-paced environment.\\n\\n\\n\\n \\xa0\\n \\n\\n\\n\\n**Nice to Have:** \\n\\n\\n\\n* Experience with\\xa0\\n **cloud\\\\-based AI services** \\n \\xa0(AWS, GCP, Azure).\\n* Familiarity with\\xa0\\n **CI/CD pipelines** \\n \\xa0for AI model deployment.\\n* Knowledge of other AI frameworks and tools (e.g.,\\xa0\\n **Hugging Face, Keras, Scikit\\\\-learn** \\n ).\\n* Experience in\\xa0\\n **deploying AI models to edge devices** \\n \\xa0or\\xa0\\n **mobile platforms** \\n .\\n* Familiarity with\\xa0\\n **reinforcement learning** \\n \\xa0and other advanced AI techniques.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=documentation(fetch_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'job_title': 'Consultant (Credit Risk Modelling), Data Science & Analytics', 'company': 'TransUnion', 'location': 'Pune', 'searched_city': 'Pune', 'language': 'en'}, page_content='TransUnion\\'s Job Applicant Privacy Notice\\n\\nWhat We\\'ll Bring:\\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\nWhat You\\'ll Bring:\\n\\nWhat we’ll bring:\\n  \\n\\n* A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.\\n* Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.\\n* Our culture encourages our people to hone current skills and build new capabilities while discovering their genius.\\n* We provide a modern computing environment based on best\\\\-in\\\\-class \"big data\" and cloud computing technologies and the freedom to explore new data sources and statistical and machine learning methodologies.\\n* Our Analytics team is home to some of the most brilliant minds in the market. Here, we will not only understand your stats jokes, we’ll appreciate them.\\n\\n  \\n\\nWhat you’ll bring:\\n  \\n\\n* Bachelors (4 year) degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least four (6\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Strong analytical, critical thinking, and creative problem\\\\-solving skills\\n* Excellent understanding of machine learning techniques and algorithms, such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, Gradient Boosting, etc.\\n* Advanced programming skills; proficiency with a statistical language such as R; experience using other programming and data manipulation languages preferred (SQL, Hive, Pig, Python, C/C\\\\+\\\\+, Java); high level of familiarity with Microsoft Office tools\\n* Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast\\\\-paced environment\\n* Strong project management skills with the ability to manage multiple assignments effectively\\n* Ability to travel 10\\\\-20%\\n\\n  \\n\\nWhat we\\'d prefer to see:\\n  \\n\\n* Master’s (2 years) or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least one (1\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Familiarity with credit bureau data and business practices\\n* Experienced with Tableau or other visualization tools\\n* Advanced skills using Excel formulas, macros, and pivot tables to provide detailed analytical reports.\\n* Operates under modest supervision in a complex and dynamic, matrixed environment\\n* Experienced working in a company with a global presence\\n* Experience with modern \"big data\" frameworks (Hadoop, Spark, cloud)\\n\\n  \\n\\n  \\n\\nImpact you’ll make:\\n  \\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n  \\n\\n  \\n\\n* You will partner with internal and external cross\\\\-functional teams to drive new business initiatives and deliver long term value\\\\-added product propositions for TU’s B2B customers globally. This includes but is not limited to developing predictive risk management and business intelligence solutions for credit card issuers, auto \\\\& mortgage lenders, collections agencies, and retail banks.\\n* You will contribute in analytic engagements involving descriptive, predictive, and prescriptive analysis through the consumer lending portfolio lifecycle, leveraging various techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).\\n* You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, Python, SQL, Hive, and Spark on server and cloud based computing platforms.\\n* You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.\\n* You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.\\n* You will foster a high performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.\\nImpact You\\'ll Make:\\n\\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\\n\\nThis is a hybrid position and involves regular performance of job responsibilities virtually as well as in\\\\-person at an assigned TU office location for a minimum of two days a week.\\nTransUnion Job Title\\n\\nConsultant, Data Science and Analytics')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Determine if the following text describes a job role. \n",
    "    Answer strictly 'Yes' or 'No'.\n",
    "    \n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def is_job_role(text):\n",
    "    # Format the prompt with the input text\n",
    "    formatted_prompt = prompt.format(text=text)\n",
    "    \n",
    "    \n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_job_role(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1500,chunk_overlap=200)\n",
    "\n",
    "text_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arshi\\Downloads\\Desktop\\Bro-Project\\SkillForge.ai\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store=FAISS.from_documents(text_chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=embeddings.embed_query(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_sample=vectore_store.as_retriever(search_type='similarity',search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='013abf22-a78a-4004-ac88-a2972a685b24', metadata={'job_title': 'Data Analyst', 'company': 'Jaipur Rugs', 'location': 'Jaipur, Rajasthan, India', 'searched_city': 'Jaipur', 'language': 'en'}, page_content='• Proficiency with Microsoft Office applications, with expertise in Excel (e.g., pivot tables, advanced functions, formulas, filtering, etc.) and database skills (e.g., SQL)\\n \\n\\n • Ability to collect and synthesize information, making it relevant, understandable, and actionable for key stakeholders\\n \\n\\n • Ability to balance multiple projects with competing deadlines\\n \\n\\n • Generate insights that improve the business through linking various data sources\\n \\n\\n • Strong understanding of Analytics and Visualization techniques'),\n",
       " Document(id='dde3b1e9-dc9d-43e1-a53f-a54e1db062f0', metadata={'job_title': 'Data Analyst', 'company': 'Jaipur Rugs', 'location': 'Jaipur, Rajasthan, India', 'searched_city': 'Jaipur', 'language': 'en'}, page_content='• Working knowledge in data management and analytics platforms, such as SQL Server, SSIS, Power BI, and Google Analytics. • Demonstrated ability in statistical analysis, predictive modeling, and machine learning techniques.\\n \\n\\n • Demonstrated ability to analyze and interpret trends in large datasets, identifying patterns and insights that drive strategic decision\\\\-making.\\n \\n\\n • Familiarity with ERP systems and their application in data\\\\-driven business environments.\\n \\n\\n • Experience in implementing tailored solutions to improve customer journey mapping, satisfaction metrics, and brand loyalty.\\n \\n\\n • Proficiency in warehouse management tools, demonstrating expertise in utilizing data analytics to optimize supply chain operations and enhance efficiency within warehouse management systems.\\n \\n\\n • Ability to communicate trends and their implications clearly and concisely to stakeholders at all levels of the organization, informing strategic planning and resource allocation.\\n \\n\\n • Strong project management skills, presentation skills, and a successful track record of leading successful cross\\\\-functional initiatives.\\n \\n\\n • Demonstrated track record of working with consumer brand initiatives or enhancing customer experiences through data\\\\-driven strategies.\\n \\n\\n  \\n\\nSpecialized Training or Knowledge: \\n\\n • Proficiency with Microsoft Office applications, with expertise in Excel (e.g., pivot tables, advanced functions, formulas, filtering, etc.) and database skills (e.g., SQL)'),\n",
       " Document(id='ccdab826-ca4c-4a9e-9f84-0c93ea526826', metadata={'job_title': 'Data Analyst', 'company': 'Jaipur Rugs', 'location': 'Jaipur, Rajasthan, India', 'searched_city': 'Jaipur', 'language': 'en'}, page_content=\"• Legacy: Comfortable with creating foundational data strategy that will enable a hyper growth strategy.\\n \\n\\n • Data Governance: Ensure data integrity and consistency across all reporting, documentation of data assets and KPIs, establish source of truth for data domains. Implement data quality standards and procedures, overseeing data cleansing and validation processes.\\n \\n\\n • Technical Expertise: Utilize SSIS for ETL processes, ensuring seamless data integration and automation across systems. Employ Power BI for comprehensive business intelligence solutions, creating dynamic reports and dashboards that drive decision\\\\-making\\n \\n\\n • Continuous Improvement: Stay informed about industry trends and emerging technologies in data and analytics. Identify opportunities for process optimization and the application of advanced analytics techniques and build a 3\\\\-year roadmap for data analytics.\\n \\n\\n  \\n\\nSkills \\\\& Minimum Qualifications: \\n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of knowledge, skill, and/or ability required. Reasonable accommodation may be made to enable individuals with disabilities to perform essential functions.\\n \\n\\n • Bachelors or Master's in Data Science, Computer Science, or related fields. • At least 7 years of experience in a leadership role within analytics/data science, specifically within the retail or ecommerce sector.\")]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_sample.invoke(\"what are skills required for data science job role \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store.save_local('job_vector_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\"\"\"You are a friendly and knowledgeable AI career mentor.  Your role is to provide insightful and helpful career\n",
    "        advice to users based on real-world job market data. You will use information on job skills, and required qualifications to \n",
    "        provide assistance. If you don't know the answer, provide alternative options and be honest about what you don't know.\n",
    "\n",
    "        Instructions:\n",
    "        1.  Carefully analyze the context provided, which contains relevant job descriptions and extracted skills.\n",
    "        2.  Based on the context, answer the user's question in a clear, concise, and easy-to-understand manner.\n",
    "        3.  If the query cannot be accurately answered based on the context, admit that you lack sufficient information and suggest \n",
    "        rephrasing the query or providing more details.\n",
    "        4.  Avoid making up information or providing speculative answers.\n",
    "\n",
    "        Context: {context}\n",
    "        \"\"\")\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',system_prompt), \n",
    "        ('human',\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain,create_history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain=create_stuff_documents_chain(llm,prompt1)\n",
    "retriever=vectore_store.as_retriever(search_type='similarity',search_kwargs={'k':3})\n",
    "retriever_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2='How can I transition from a data analyst to a data scientist role?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retriever_chain.invoke({'input':inputs2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitioning from a data analyst to a data scientist role requires a combination of skills, experience, and dedication. Based on the job brief provided, here are some key takeaways to help you make this transition:\n",
      "\n",
      "1. **Develop advanced analytical skills**: As a data analyst, you likely have a strong foundation in data analysis. To become a data scientist, you'll need to develop skills in machine learning, programming languages like Python, R, or SQL, and experience with data manipulation and visualization tools.\n",
      "2. **Gain experience with machine learning techniques**: The job brief mentions specific machine learning algorithms like Classification, Regression, Clustering, and Decision Trees. Familiarize yourself with these techniques and practice implementing them using popular libraries like scikit-learn or TensorFlow.\n",
      "3. **Improve your programming skills**: Data scientists need to be proficient in programming languages like Python, R, or SQL. Focus on developing your skills in one or more of these languages, and learn to work with popular data science libraries and frameworks.\n",
      "4. **Learn data governance and data quality**: As a data scientist, you'll be responsible for ensuring data integrity and consistency. Study data governance principles, data quality standards, and learn to implement data validation and cleansing processes.\n",
      "5. **Stay up-to-date with industry trends and emerging technologies**: The job brief mentions the importance of staying informed about industry trends and emerging technologies in data and analytics. Attend conferences, read industry blogs, and participate in online forums to stay current.\n",
      "6. **Develop strong communication and project management skills**: As a data scientist, you'll need to communicate complex technical concepts to non-technical stakeholders and manage multiple projects effectively. Practice presenting your findings and results to different audiences, and develop your project management skills to prioritize tasks and meet deadlines.\n",
      "7. **Consider pursuing a graduate degree or certifications**: While not necessary, a Master's degree in Data Science, Computer Science, or a related field can be beneficial for advanced roles. Additionally, consider obtaining certifications like Certified Data Scientist (CDS) or Certified Analytics Professional (CAP) to demonstrate your expertise.\n",
      "8. **Network and build a professional portfolio**: Connect with other data professionals, attend industry events, and build a portfolio of your work to showcase your skills and experience to potential employers.\n",
      "\n",
      "In terms of specific skills, focus on developing:\n",
      "\n",
      "* Programming skills in Python, R, or SQL\n",
      "* Experience with machine learning libraries like scikit-learn, TensorFlow, or PyTorch\n",
      "* Data visualization skills using tools like Tableau, Power BI, or D3.js\n",
      "* Data governance and data quality principles\n",
      "* Strong communication and project management skills\n",
      "\n",
      "By following these steps and focusing on developing the necessary skills, you can increase your chances of successfully transitioning from a data analyst to a data scientist role.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about malaria in the provided context, which appears to be a job description for a Consultant, Data Science and Analytics position at TransUnion. The context discusses roles and responsibilities related to mobile app development, team management, and data science, but it does not mention malaria.\n",
      "\n",
      "If you're looking for information about malaria, I suggest searching for it on a reliable health or medical website, such as the World Health Organization (WHO) or the Centers for Disease Control and Prevention (CDC). They should have accurate and up-to-date information about malaria, its causes, symptoms, treatment, and prevention.\n"
     ]
    }
   ],
   "source": [
    "input2='What is malaria?'\n",
    "response2=retriever_chain.invoke({'input':input2})\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory,InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt  = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history,\"\n",
    "    \"Formulate a standalone query which can be understood without the chat history.\"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return as it is.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        ('human',\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(llm,retriever,contextualize_q_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, the following Python libraries are highly in-demand for Data Science roles:\n",
      "\n",
      "1. **NumPy**: The NumPy library is a fundamental library for numerical computing in Python, and is widely used in Data Science for tasks such as data manipulation and analysis.\n",
      "2. **Pandas**: The Pandas library is a powerful library for data manipulation and analysis, and is widely used in Data Science for tasks such as data cleaning, filtering, and grouping.\n",
      "3. **Matplotlib** and **Seaborn**: These libraries are widely used for data visualization, and are essential for creating informative and engaging visualizations.\n",
      "4. **Scikit-learn**: The Scikit-learn library is a widely used library for machine learning, and provides a wide range of algorithms for tasks such as classification, regression, clustering, and more.\n",
      "5. **TensorFlow** or **PyTorch**: These libraries are widely used for deep learning, and provide a wide range of tools and frameworks for building and training neural networks.\n",
      "6. **Flask** or **FastAPI**: These libraries are widely used for building REST APIs, and are essential for deploying Data Science models in production environments.\n",
      "7. **Scipy**: The Scipy library is a widely used library for scientific computing, and provides a wide range of tools and functions for tasks such as signal processing, linear algebra, and optimization.\n",
      "\n",
      "Additionally, having experience with other libraries such as **Keras**, **OpenCV**, and **NLTK** can also be beneficial for Data Science roles, particularly those involving computer vision, natural language processing, or other specialized areas.\n",
      "\n",
      "It's worth noting that the specific libraries and tools required may vary depending on the organization, industry, or specific job role. However, having a strong foundation in the above-mentioned libraries will provide a solid foundation for a career in Data Science.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What are the key skills I need to become a Data Scientist in the current job market?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_question = \"Okay, that's helpful. You mentioned Python. Which specific Python libraries are most in-demand for Data Science roles right now?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What are the key skills I need to become a Data Scientist in the current job market?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Based on the context provided, to become a Data Scientist in the current job market, you should possess the following key skills:\\n\\n1. **Data Management and Analytics**: Working knowledge of data management and analytics platforms such as SQL Server, SSIS, Power BI, and Google Analytics.\\n2. **Statistical Analysis and Machine Learning**: Demonstrated ability in statistical analysis, predictive modeling, and machine learning techniques, including algorithms like Classification, Regression, Clustering, Feature Engineering, Decision Trees, and Gradient Boosting.\\n3. **Data Visualization and Communication**: Ability to communicate trends and insights clearly and concisely to stakeholders at all levels of the organization, using techniques such as data visualization and presentation skills.\\n4. **Programming Skills**: Advanced programming skills, including proficiency in a statistical language like R, and experience with other programming languages like SQL, Hive, Pig, Python, C/C++, and Java.\\n5. **Data Warehouse Management**: Familiarity with warehouse management tools and expertise in utilizing data analytics to optimize supply chain operations and enhance efficiency within warehouse management systems.\\n6. **Project Management**: Strong project management skills, with the ability to manage multiple assignments effectively and lead cross-functional initiatives.\\n7. **Business Acumen**: Ability to analyze and interpret trends in large datasets, identifying patterns and insights that drive strategic decision-making and inform business planning.\\n8. **ERP Systems**: Familiarity with ERP systems and their application in data-driven business environments.\\n9. **Microsoft Office**: Proficiency with Microsoft Office applications, particularly Excel (e.g., pivot tables, advanced functions, formulas, filtering) and database skills (e.g., SQL).\\n10. **Interpersonal and Communication Skills**: Versatile interpersonal and communication style, with the ability to effectively communicate at multiple levels within and outside the organization.\\n\\nAdditionally, having a Bachelor's degree in a quantitative field (e.g., statistics, applied mathematics, financial mathematics, engineering, operations research) and at least 4-6 years of professional experience in analytics or a related field is highly preferred.\\n\\nKeep in mind that the specific requirements may vary depending on the organization, industry, or specific job role. However, possessing these key skills will provide a solid foundation for a career as a Data Scientist in the current job market.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the context provided, to become a Data Scientist in the current job market, you'll need to possess a combination of technical, business, and soft skills. Here are the key skills required:\\n\\n**Technical Skills:**\\n\\n1. **Programming skills**: Proficiency in languages such as Python, R, SQL, and Java.\\n2. **Data management and analytics**: Experience with data management and analytics platforms like SQL Server, SSIS, Power BI, and Google Analytics.\\n3. **Machine learning and statistical analysis**: Knowledge of machine learning techniques, statistical analysis, and predictive modeling.\\n4. **Data visualization**: Familiarity with data visualization tools and techniques to effectively communicate insights.\\n5. **Database skills**: Understanding of database concepts and experience with database management systems.\\n\\n**Business and Quantitative Skills:**\\n\\n1. **Quantitative field**: A degree in a quantitative field such as statistics, applied mathematics, financial mathematics, engineering, or operations research.\\n2. **Data-driven decision making**: Ability to analyze and interpret trends in large datasets to drive strategic decision-making.\\n3. **ERP systems**: Familiarity with Enterprise Resource Planning (ERP) systems and their application in data-driven business environments.\\n4. **Supply chain operations**: Knowledge of optimizing supply chain operations using data analytics.\\n\\n**Soft Skills:**\\n\\n1. **Communication**: Ability to communicate complex trends and insights clearly and concisely to stakeholders at all levels.\\n2. **Project management**: Strong project management skills to manage multiple assignments and lead cross-functional initiatives.\\n3. **Collaboration**: Ability to work in a collaborative, fast-paced environment and effectively communicate with team members.\\n4. **Time management**: Ability to balance multiple projects with competing deadlines.\\n\\n**Preferred Skills:**\\n\\n1. **Advanced programming skills**: Experience with programming languages like C/C++, Hive, Pig, and Python.\\n2. **Machine learning algorithms**: Knowledge of machine learning algorithms such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, and Gradient Boosting.\\n3. **Microsoft Office tools**: Proficiency with Microsoft Office applications, particularly Excel, and database skills like SQL.\\n\\nTo become a successful Data Scientist, focus on developing a strong foundation in technical, business, and soft skills, and stay up-to-date with industry trends and advancements.\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are the key skills I need to become a Data Scientist in the current job market?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What are the key skills I need to become a Data Scientist in the current job market?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on the context provided, to become a Data Scientist in the current job market, you'll need to possess a combination of technical, business, and soft skills. Here are the key skills required:\\n\\n**Technical Skills:**\\n\\n1. **Programming skills**: Proficiency in languages such as Python, R, SQL, and Java.\\n2. **Data management and analytics**: Experience with data management and analytics platforms like SQL Server, SSIS, Power BI, and Google Analytics.\\n3. **Machine learning and statistical analysis**: Knowledge of machine learning techniques, statistical analysis, and predictive modeling.\\n4. **Data visualization**: Familiarity with data visualization tools and techniques to effectively communicate insights.\\n5. **Database skills**: Understanding of database concepts and experience with database management systems.\\n\\n**Business and Quantitative Skills:**\\n\\n1. **Quantitative field**: A degree in a quantitative field such as statistics, applied mathematics, financial mathematics, engineering, or operations research.\\n2. **Data-driven decision making**: Ability to analyze and interpret trends in large datasets to drive strategic decision-making.\\n3. **ERP systems**: Familiarity with Enterprise Resource Planning (ERP) systems and their application in data-driven business environments.\\n4. **Supply chain operations**: Knowledge of optimizing supply chain operations using data analytics.\\n\\n**Soft Skills:**\\n\\n1. **Communication**: Ability to communicate complex trends and insights clearly and concisely to stakeholders at all levels.\\n2. **Project management**: Strong project management skills to manage multiple assignments and lead cross-functional initiatives.\\n3. **Collaboration**: Ability to work in a collaborative, fast-paced environment and effectively communicate with team members.\\n4. **Time management**: Ability to balance multiple projects with competing deadlines.\\n\\n**Preferred Skills:**\\n\\n1. **Advanced programming skills**: Experience with programming languages like C/C++, Hive, Pig, and Python.\\n2. **Machine learning algorithms**: Knowledge of machine learning algorithms such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, and Gradient Boosting.\\n3. **Microsoft Office tools**: Proficiency with Microsoft Office applications, particularly Excel, and database skills like SQL.\\n\\nTo become a successful Data Scientist, focus on developing a strong foundation in technical, business, and soft skills, and stay up-to-date with industry trends and advancements.\", additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, the following Python libraries are in high demand for Data Science roles:\\n\\n1. **NumPy**: The NumPy library is a fundamental library for numerical computing in Python, and is widely used in Data Science for tasks such as data manipulation and analysis.\\n2. **Pandas**: The Pandas library is a powerful library for data manipulation and analysis, and is widely used in Data Science for tasks such as data cleaning, filtering, and grouping.\\n3. **Scikit-learn**: The Scikit-learn library is a popular library for machine learning in Python, and is widely used in Data Science for tasks such as classification, regression, clustering, and model selection.\\n4. **TensorFlow** or **PyTorch**: Both TensorFlow and PyTorch are popular deep learning libraries in Python, and are widely used in Data Science for tasks such as building and training neural networks.\\n5. **Matplotlib** and/or **Seaborn**: Both Matplotlib and Seaborn are popular data visualization libraries in Python, and are widely used in Data Science for tasks such as creating plots, charts, and heatmaps.\\n6. **Flask** or **FastAPI**: Both Flask and FastAPI are popular libraries for building REST APIs in Python, and are widely used in Data Science for tasks such as deploying machine learning models and creating data-driven web applications.\\n\\nThese libraries are mentioned in the context as essential skills for the AI/ML Developer role, and are widely used in the industry for Data Science tasks. Having experience with these libraries can be beneficial for a career in Data Science.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Okay, that's helpful. You mentioned Python. Which specific Python libraries are most in-demand for Data Science roles right now?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
