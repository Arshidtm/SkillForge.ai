{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "welcome\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('welcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv('RAPIDAPI_KEY')\n",
    "\n",
    "INDIAN_CITIES = [\n",
    "    \"Mumbai\", \"Delhi\", \"Bangalore\", \"Hyderabad\", \"Ahmedabad\",\n",
    "    \"Chennai\", \"Kolkata\", \"Surat\", \"Pune\", \"Jaipur\",\n",
    "    \"Lucknow\", \"Kanpur\", \"Nagpur\", \"Visakhapatnam\", \"Indore\",\n",
    "    \"Thane\", \"Bhopal\", \"Patna\", \"Vadodara\", \"Ghaziabad\"\n",
    "]\n",
    "\n",
    "def fetch_jobs(query, location=\"India\", results_wanted=5,api_key=api_key):\n",
    "    conn = http.client.HTTPSConnection(\"jobs-search-api.p.rapidapi.com\")\n",
    "    \n",
    "    # If location is \"India\", use random cities\n",
    "    if location.lower() == \"india\":\n",
    "        # Calculate how many jobs per city (at least 1 city per job)\n",
    "        jobs_per_city = max(1, results_wanted // len(INDIAN_CITIES))\n",
    "        all_jobs = []\n",
    "        \n",
    "        for city in random.sample(INDIAN_CITIES, min(len(INDIAN_CITIES), results_wanted)):\n",
    "            payload = json.dumps({\n",
    "                \"search_term\": query,\n",
    "                \"location\": f\"{city}, India\",\n",
    "                \"results_wanted\": jobs_per_city,\n",
    "                \"site_name\": [\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "                \"distance\": 50,\n",
    "                \"job_type\": \"fulltime\",\n",
    "                \"is_remote\": False,\n",
    "                \"linkedin_fetch_description\": True,\n",
    "                \"hours_old\": 72\n",
    "            })\n",
    "\n",
    "            headers = {\n",
    "\t'x-rapidapi-key': api_key,\n",
    "    'x-rapidapi-host': \"jobs-search-api.p.rapidapi.com\",\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "\n",
    "            try:\n",
    "                conn.request(\"POST\", \"/getjobs\", body=payload, headers=headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                city_jobs = json.loads(data).get(\"jobs\", [])\n",
    "                \n",
    "                # Add city information to each job\n",
    "                for job in city_jobs:\n",
    "                    job[\"searched_location\"] = city\n",
    "                all_jobs.extend(city_jobs)\n",
    "                \n",
    "                # Stop if we've collected enough jobs\n",
    "                if len(all_jobs) >= results_wanted:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching jobs for {city}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        # Trim to exact result count and format\n",
    "        return [\n",
    "            {\n",
    "                \"job title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"location\": job.get(\"location\", \"N/A\"),\n",
    "                \"searched_city\": job.get(\"searched_location\", \"India\"),\n",
    "                \"description\": job[\"description\"]\n",
    "            }\n",
    "            for job in all_jobs[:results_wanted]\n",
    "            if all(key in job for key in [\"title\", \"company\", \"description\"])\n",
    "        ]\n",
    "    \n",
    "    else:\n",
    "        # Original single-location logic\n",
    "        payload = json.dumps({\n",
    "            \"search_term\": query,\n",
    "            \"location\": location,\n",
    "            \"results_wanted\": results_wanted,\n",
    "            \"site_name\": [\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\"],\n",
    "            \"distance\": 50,\n",
    "            \"job_type\": \"fulltime\",\n",
    "            \"is_remote\": False,\n",
    "            \"linkedin_fetch_description\": True,\n",
    "            \"hours_old\": 72,\n",
    "            \"show_requirements\": True, \n",
    "        })\n",
    "\n",
    "        headers = {\n",
    "\t'x-rapidapi-key': api_key,\n",
    "    'x-rapidapi-host': \"jobs-search-api.p.rapidapi.com\",\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "\n",
    "        conn.request(\"POST\", \"/getjobs\", body=payload, headers=headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read().decode(\"utf-8\")\n",
    "        job_data = json.loads(data)\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"job title\": job[\"title\"],\n",
    "                \"company\": job[\"company\"],\n",
    "                \"location\": job.get(\"location\", \"N/A\"),\n",
    "                \"searched_city\": location.split(\",\")[0].strip(),\n",
    "                \"description\": job[\"description\"]\n",
    "            }\n",
    "            for job in job_data.get(\"jobs\", [])\n",
    "            if all(key in job for key in [\"title\", \"company\", \"description\"])\n",
    "        ]\n",
    "        \n",
    "def clean_text(text):\n",
    "    \"\"\"Remove excessive newlines and markdown bold syntax\"\"\"\n",
    "    text = re.sub(r'\\*\\*', '', text)  # Remove **bold** markers\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)  # Replace 3+ newlines with double newlines\n",
    "    return text.strip()\n",
    "\n",
    "def documentation(job_details):\n",
    "    content=[] \n",
    "    for job in job_details: \n",
    "        doc = Document(\n",
    "                page_content=clean_text(job[\"description\"]),\n",
    "                metadata={\n",
    "                    \"job_title\": job[\"job title\"],\n",
    "                    \"company\": job[\"company\"],\n",
    "                    \"location\": job[\"location\"],\n",
    "                    \"searched_city\": job[\"searched_city\"],\n",
    "                    \n",
    "                    \"language\": \"en\"\n",
    "                    }\n",
    "                )\n",
    "        content.append(doc)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs='Data Science'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_jobs=fetch_jobs(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job title': 'Consultant (Credit Risk Modelling), Data Science & Analytics',\n",
       "  'company': 'TransUnion',\n",
       "  'location': 'Pune',\n",
       "  'searched_city': 'Pune',\n",
       "  'description': 'TransUnion\\'s Job Applicant Privacy Notice\\n\\n\\n**What We\\'ll Bring:**\\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n**What You\\'ll Bring:**\\n\\nWhat we’ll bring:\\n  \\n\\n* A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.\\n* Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.\\n* Our culture encourages our people to hone current skills and build new capabilities while discovering their genius.\\n* We provide a modern computing environment based on best\\\\-in\\\\-class \"big data\" and cloud computing technologies and the freedom to explore new data sources and statistical and machine learning methodologies.\\n* Our Analytics team is home to some of the most brilliant minds in the market. Here, we will not only understand your stats jokes, we’ll appreciate them.\\n\\n  \\n\\nWhat you’ll bring:\\n  \\n\\n* Bachelors (4 year) degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least four (6\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Strong analytical, critical thinking, and creative problem\\\\-solving skills\\n* Excellent understanding of machine learning techniques and algorithms, such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, Gradient Boosting, etc.\\n* Advanced programming skills; proficiency with a statistical language such as R; experience using other programming and data manipulation languages preferred (SQL, Hive, Pig, Python, C/C\\\\+\\\\+, Java); high level of familiarity with Microsoft Office tools\\n* Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast\\\\-paced environment\\n* Strong project management skills with the ability to manage multiple assignments effectively\\n* Ability to travel 10\\\\-20%\\n\\n  \\n\\nWhat we\\'d prefer to see:\\n  \\n\\n* Master’s (2 years) or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least one (1\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Familiarity with credit bureau data and business practices\\n* Experienced with Tableau or other visualization tools\\n* Advanced skills using Excel formulas, macros, and pivot tables to provide detailed analytical reports.\\n* Operates under modest supervision in a complex and dynamic, matrixed environment\\n* Experienced working in a company with a global presence\\n* Experience with modern \"big data\" frameworks (Hadoop, Spark, cloud)\\n\\n  \\n\\n  \\n\\nImpact you’ll make:\\n  \\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n  \\n\\n  \\n\\n* You will partner with internal and external cross\\\\-functional teams to drive new business initiatives and deliver long term value\\\\-added product propositions for TU’s B2B customers globally. This includes but is not limited to developing predictive risk management and business intelligence solutions for credit card issuers, auto \\\\& mortgage lenders, collections agencies, and retail banks.\\n* You will contribute in analytic engagements involving descriptive, predictive, and prescriptive analysis through the consumer lending portfolio lifecycle, leveraging various techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).\\n* You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, Python, SQL, Hive, and Spark on server and cloud based computing platforms.\\n* You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.\\n* You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.\\n* You will foster a high performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.\\n**Impact You\\'ll Make:**\\n\\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\\n\\n\\nThis is a hybrid position and involves regular performance of job responsibilities virtually as well as in\\\\-person at an assigned TU office location for a minimum of two days a week.\\nTransUnion Job Title\\n\\n\\nConsultant, Data Science and Analytics'},\n",
       " {'job title': 'Data Scientist',\n",
       "  'company': 'LTIMindtree',\n",
       "  'location': 'Pune, Maharashtra, India',\n",
       "  'searched_city': 'Pune',\n",
       "  'description': 'LTIMindtree is looking for Data Scientist Role\\n \\n\\n\\n\\n Experience\\\\- 5 to 8 Years\\n \\n\\n\\n\\n Job Location\\\\- Pune\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n Data Scientist\\n \\n\\n\\n\\n Strong problemsolving skills and ability to deliver highquality datafocused solutions\\n \\n\\n\\n\\n Proficiency in Python SQL and expertise in machine learning and deep learning algorithms\\n \\n\\n\\n\\n Experience with generative AI and LangChain for building and deploying advanced models\\n \\n\\n\\n\\n Proficiency in Azure cloud services for implementing and managing AI solutions\\n \\n\\n\\n\\n Drive the development of impactful data products to support business objectives\\n \\n\\n\\n\\n\\n\\n\\n\\n Skills\\\\-Machine Learning, Deep Learing, Python, Pytorch, Cloud,AI, Gen AI exp mandatory\\n \\n\\n\\n\\n If interested please share below details on darshana.potdukhe@ltimindtree.com\\n \\n\\n\\n\\n Total Experience:\\n \\n\\n\\n\\n Current CTC:\\n \\n\\n\\n\\n Expected CTC:\\n \\n\\n\\n\\n Official NP: (If serving last working day)'},\n",
       " {'job title': 'Data Analyst',\n",
       "  'company': 'Jaipur Rugs',\n",
       "  'location': 'Jaipur, Rajasthan, India',\n",
       "  'searched_city': 'Jaipur',\n",
       "  'description': \"**Job brief** \\n\\n\\n\\n\\n We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n As the Lead \\\\- Analytics, you will lead our strategic efforts to leverage data in alignment with our business objectives. Your role will be pivotal in fostering a culture of analytics, implementing best practices, and improving data\\\\-driven decision making. You will align and direct the development, management, and integration of our analytics and business intelligence (BI) capability to support the mission, vision, objectives, and goals of the overall business. Additionally, we seek someone who comprehensively understands how the business operates as a whole, recognizing the importance of analytics in each department to paint a cohesive and comprehensive picture.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Essential Responsibilities:** \\n\\n\\n\\n\\n • Strategic Leadership: Drive a culture of Business Intelligence by assisting in architecting and executing a visionary analytics strategy that harnesses our data ecosystem. Responsible for driving departmental adoption of analytics while promoting data\\\\-driven decision\\\\-making and customer\\\\- and consumer\\\\-driven insights.\\n \\n\\n\\n\\n • Excellent Communication \\\\& Coordination: Since the position will primarily be coordinating \\\\& working with our U.S office team, hence excellent command over verbal \\\\& written English is an important pre\\\\-requisite for the position. Ideal candidate should be open for working as per US shift timings.\\n \\n\\n\\n\\n • Analytics Infrastructure: Collaborate with IT Architecture Leadership around the development and maintenance of robust analytics infrastructure, including data warehouses, reporting tools, and visualization platforms.\\n \\n\\n\\n\\n • Analytics and Modeling: Establish a foundation for deploying advanced statistical models and machine learning algorithms in the future, focusing on building the necessary infrastructure and expertise for predictive analysis and optimization.\\n \\n\\n\\n\\n • Dashboard and KPI Management: Develop dashboards and KPIs to drive decision\\x02making processes.\\n \\n\\n\\n\\n • Collaboration and Influence: Collaborate with key stakeholders across departments to understand business needs and translate them into data and analytics requirements. Act as a bridge between technical teams and business units, translating complex data insights into actionable business strategies. Effective communication with both technical and non\\\\-technical team members.\\n \\n\\n\\n\\n • Legacy: Comfortable with creating foundational data strategy that will enable a hyper growth strategy.\\n \\n\\n\\n\\n • Data Governance: Ensure data integrity and consistency across all reporting, documentation of data assets and KPIs, establish source of truth for data domains. Implement data quality standards and procedures, overseeing data cleansing and validation processes.\\n \\n\\n\\n\\n • Technical Expertise: Utilize SSIS for ETL processes, ensuring seamless data integration and automation across systems. Employ Power BI for comprehensive business intelligence solutions, creating dynamic reports and dashboards that drive decision\\\\-making\\n \\n\\n\\n\\n • Continuous Improvement: Stay informed about industry trends and emerging technologies in data and analytics. Identify opportunities for process optimization and the application of advanced analytics techniques and build a 3\\\\-year roadmap for data analytics.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Skills \\\\& Minimum Qualifications:** \\n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of knowledge, skill, and/or ability required. Reasonable accommodation may be made to enable individuals with disabilities to perform essential functions.\\n \\n\\n\\n\\n • Bachelors or Master's in Data Science, Computer Science, or related fields. • At least 7 years of experience in a leadership role within analytics/data science, specifically within the retail or ecommerce sector.\\n \\n\\n\\n\\n • Working knowledge in data management and analytics platforms, such as SQL Server, SSIS, Power BI, and Google Analytics. • Demonstrated ability in statistical analysis, predictive modeling, and machine learning techniques.\\n \\n\\n\\n\\n • Demonstrated ability to analyze and interpret trends in large datasets, identifying patterns and insights that drive strategic decision\\\\-making.\\n \\n\\n\\n\\n • Familiarity with ERP systems and their application in data\\\\-driven business environments.\\n \\n\\n\\n\\n • Experience in implementing tailored solutions to improve customer journey mapping, satisfaction metrics, and brand loyalty.\\n \\n\\n\\n\\n • Proficiency in warehouse management tools, demonstrating expertise in utilizing data analytics to optimize supply chain operations and enhance efficiency within warehouse management systems.\\n \\n\\n\\n\\n • Ability to communicate trends and their implications clearly and concisely to stakeholders at all levels of the organization, informing strategic planning and resource allocation.\\n \\n\\n\\n\\n • Strong project management skills, presentation skills, and a successful track record of leading successful cross\\\\-functional initiatives.\\n \\n\\n\\n\\n • Demonstrated track record of working with consumer brand initiatives or enhancing customer experiences through data\\\\-driven strategies.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**Specialized Training or Knowledge:** \\n\\n\\n\\n\\n • Proficiency with Microsoft Office applications, with expertise in Excel (e.g., pivot tables, advanced functions, formulas, filtering, etc.) and database skills (e.g., SQL)\\n \\n\\n\\n\\n • Ability to collect and synthesize information, making it relevant, understandable, and actionable for key stakeholders\\n \\n\\n\\n\\n • Ability to balance multiple projects with competing deadlines\\n \\n\\n\\n\\n • Generate insights that improve the business through linking various data sources\\n \\n\\n\\n\\n • Strong understanding of Analytics and Visualization techniques\"},\n",
       " {'job title': 'iOS Team Lead',\n",
       "  'company': 'Optimumbrew Technology',\n",
       "  'location': 'India',\n",
       "  'searched_city': 'Surat',\n",
       "  'description': '**We are looking for talented iOS Team Leader who are passionate and know\\\\-how the process of building scalable and secure functionality on top of the iOS platform. You will be associated with a qualified and experienced pool of people with whom you will build correlations by sharing your experience and growing your capabilities.**\\n\\n**Primary Objectives**\\n\\n* Experience in leading a small group of team members.\\n* Professional experience with swift code for iOS.\\n* Practical experience in applying OOPs techniques and design patterns in everyday coding.\\n* Expertise of iOS SDK, different versions of iOS, and how to deal with different screen sizes.\\n* Experience working with remote data via REST API and JSON.\\n* Proper knowledge of the iOS development life cycle.\\n* Understanding of iOS App Code signing process and deployment process.\\n* Ability to understand business requirements and translate them into technical requirements.\\n* Experience with offline storage, threading, and performance tuning.\\n* Experience with development in third\\\\-party libraries, and APIs.The desire to be continually learning about newly emerging technologies/industry\\n* trends \\\\& challenges, perform duties with minimal guidance.\\n* Solid hands\\\\-on experience in developing native iOS apps.\\n* Hands\\\\-on experience in Cloud APIs, push notifications, Social sign\\\\-in, Crashlytics,\\n* integration of analytics is an added advantage.\\n* Proficient understanding of code versioning tools, such as Git, SVN.\\n* Experience with performance and memory tuning with tools.\\n* Proven leadership skills, including the ability to motivate and lead other talented developers.\\n* Ability to take a project from scoping requirements through launch.\\n* Experience in dealing with multiple projects.\\n* Understanding and familiarity with common code review methods and standards.\\n* Experience building and delivering highly scalable, reliable, and complex software\\n* systems on – time and on budget.\\n* Should be ready to learn new things and take challenges.\\n\\n**Roles \\\\& Responsibilities**\\n\\n* Bring your own unique expertise to the team and learn from others.\\n* Take ownership, be creative, and think outside the box to invent and build solutions\\n* to real\\\\-world customer problems.\\n* Providing technical leadership and guidance on project plans and delivery commitments.\\n* Manage the day\\\\-to\\\\-day activities of an engineering team. Project planning,\\n* milestones/deadlines date definition, task estimation, scope of work assessment, etc.\\n* Participating in the recruitment process, providing input for performance appraisals.\\n* Manage individual team members, both junior and senior, encouraging their\\n* professional growth and maximizing their potential contributions. Lead in Architecting and developing new features in accordance with our product roadmap.\\n* Accountable for the team’s performance, work satisfaction, and growth.\\n* Provide thought leadership on industry best practices around design, testing, and security.\\n* Design and build advanced applications for the iOS platform.\\n* Creating app updates, including bug fixes and additional features, for release.\\n* Collaborating with UI and UX Designers, as well as Software Testers, to ensure that\\n* each app is presentable and in perfect working order.\\n* Proofreading code and correcting mistakes before each app is released.\\n* Ensure the best possible performance, quality, and responsiveness of the application.\\n* Strictly follow instructions \\\\& guidelines given by a project manager.\\n* Help maintain code quality, organization and automation.\\n* Fully responsible for mobile app development in the team.\\n* Work on improving application performance.\\n* Monitoring app reviews to detect areas for improvement.\\n* Continuously discover new ways to implement new technologies to improve\\n* development efficiency.\\n* Help your team solve problems in a way that makes sense for iOS users and our codebase.\\n* Join other developers and help to shape the direction of Android development at our company.\\n* Insist on a consistent and responsive user experience for every one of our users.\\n* Design, build, and maintain high performance, reusable, and reliable swift code.\\n* Give training to Jr. \\\\& fresher developers.\\n* Continuous Integration, and strategy, planning and execution.\\n* Manage individual team members, both junior and senior, encouraging their professional growth and maximizing their potential contributions.\\n* Accountable for the team’s performance, work satisfaction and growth.\\n* Establish ways for team members to complete their tasks.\\n* Define milestones for a new project.\\n* Assign targets to the team, and ensure that the targets are met.\\n* Suggest new things \\\\& methods of work to the team as \\\\& when required.\\n* Check the status of assigned tasks daily and resolve issues the team members face.\\n\\n**Technical Skills You Should Have**\\n\\n* Positive thinking and motivator for other team members.\\n* Great team player who works well in collaborative situations.\\n* A breadth of technical skills and know how to use the right tool for the job.\\n* A positive can\\\\-do attitude and bring a passion for excellence to the workplace.\\n* Translate designs and wireframes into high quality code.\\n* Excellent understanding of Swift, Xcode, Core Data, Auto Layout, Git, iOS Human\\n* Interface Guidelines, REST APIs and JSON.\\n* Understand business requirements and translate them into technical requirements.\\n* Excellent coding and proofreading skills.\\n* Passionate about creating great code.\\n* Complex problem solving and ability to multitask.\\n* Top\\\\-notch teamwork and communication skills.\\n* Creativity and brainstorming.\\n* Unwavering curiosity.\\n* Familiarity with continuous integration.\\n* Eagerness to embrace scalability, reliability, and performance challenges.\\n* Excellent verbal \\\\& written communication skills.\\n* Good interpersonal and decision making skills.\\n* Building Relationship with team members.\\n* A passion for technology and the ability to learn new concepts quickly.\\n* A systematic and quality\\\\-oriented way of working.\\n* Experience with task planning and estimating effort.\\n* Approach to tackle technical challenges with an open mind and desire to innovate.\\n\\n**Key Expertise**\\n\\n* Swift, Xcode, Core Data, Auto Layout, Git, iOS Human\\n* Interface Guidelines, REST APIs and JSON.\\n\\n**Qualification**\\n\\n* Bachelor’s Degree in Computer Science or Computer Engineering,\\n* B.Tech (CSE/ IT), M.Tech (CSE/IT), B.E. (CE/IT), M.E.(CE/IT)\\n\\n**Experience**\\n\\n* 4\\\\+ years of experience in iOS Team Leader\\n\\n**Benefits**\\n\\n* 22 Paid Leaves\\n* 5 Days Working\\n* Good Company Culture\\n* Health Insurance\\n* Pension Scheme\\n* Statutory Benefits (PF \\\\& ESIC)\\n* Salary on time\\n* Yearly Picnic\\n* Annual Sports Day\\n* Monthly Events\\n* Festival Celebrations\\n\\nJob Type: Full\\\\-time\\n\\nPay: Up to ₹1,200,000\\\\.00 per year\\n\\nSchedule:\\n\\n* Day shift\\n* Monday to Friday\\n\\nSupplemental Pay:\\n\\n* Performance bonus\\n\\nWork Location: In person'},\n",
       " {'job title': 'AI/ML Developer',\n",
       "  'company': 'WebOsmotic Private Limited',\n",
       "  'location': 'Surat, Gujarat, India',\n",
       "  'searched_city': 'Surat',\n",
       "  'description': 'We are seeking a skilled AI Developer with at least 2 years of experience in AI, Machine Learning (ML), Deep Learning (DL), and Computer Vision. The ideal candidate will have a strong foundation in:\\n \\n\\n\\n* Large Language Models (LLM)\\n* Retrieval\\\\-Augmented Generation (RAG) frameworks\\n* Developing, fine\\\\-tuning, and optimizing AI models\\n* Computer Vision techniques and their applications\\n\\n\\n\\n Proficiency in\\xa0\\n **Python programming** \\n \\xa0and experience in building and deploying scalable\\xa0\\n **REST APIs** \\n \\xa0(using frameworks such as Flask, FastAPI, Django) is essential.\\n \\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n**No. of Vacancies:** \\n \\xa03\\n \\n\\n\\n\\n**Qualification:** \\n\\n\\n\\n* Bachelor’s degree in Computer Science, IT, or a related field.\\n* 2\\\\+ years of proven experience in AI/ML development and Python programming.\\n* Proficiency in\\xa0\\n **Machine Learning, Deep Learning, and Artificial Intelligence** \\n \\xa0concepts.\\n* Strong portfolio showcasing AI/ML projects and achievements.\\n\\n\\n AI/ML Developer\\n \\n**Role \\\\& Responsibilities:** \\n\\n\\n\\n* Develop, fine\\\\-tune, and optimize\\xa0\\n **Large Language Models (LLMs)** \\n \\xa0and\\xa0\\n **Deep Learning models** \\n \\xa0for AI and Computer Vision applications.\\n* Implement and optimize\\xa0\\n **Retrieval\\\\-Augmented Generation (RAG)** \\n \\xa0frameworks to enhance AI model performance.\\n* Apply\\xa0\\n **agentic LLM frameworks** \\n \\xa0to build autonomous AI agents for real\\\\-world use cases.\\n* Develop\\xa0\\n **computer vision models** \\n \\xa0for tasks such as\\xa0\\n **image recognition, object detection, segmentation, and video analysis** \\n .\\n* Integrate AI and Computer Vision models into production systems through\\xa0\\n **REST APIs** \\n \\xa0and backend frameworks (\\n **Flask, FastAPI, Django** \\n ).\\n* Collaborate with cross\\\\-functional teams to design, test, and deploy AI solutions.\\n* Regularly evaluate AI models and conduct\\xa0\\n **performance optimizations** \\n \\xa0to ensure robustness and scalability.\\n* Stay updated on the latest advancements in\\xa0\\n **AI, ML, DL, and Computer Vision** \\n .\\n\\n\\n\\n \\xa0\\n \\n\\n\\n\\n**Required Skills:** \\n\\n\\n\\n* 2\\\\+ years of professional experience in\\xa0\\n **AI/ML development** \\n , with a focus on\\xa0\\n **ML, DL, and Computer Vision** \\n .\\n* Experience with\\xa0\\n **Large Language Models (LLM)** \\n \\xa0and\\xa0\\n **Retrieval\\\\-Augmented Generation (RAG) frameworks** \\n .\\n* Proficiency in\\xa0\\n **Python programming** \\n \\xa0and hands\\\\-on experience with ML/DL libraries such as\\xa0\\n **TensorFlow, PyTorch, OpenCV, etc.**\\n* Experience in designing, training, and optimizing\\xa0\\n **machine learning and deep learning models** \\n , including\\xa0\\n **computer vision tasks** \\n .\\n* Knowledge of\\xa0\\n **agentic LLM frameworks** \\n \\xa0(e.g.,\\xa0\\n **LangChain, GPT\\\\-Agents** \\n ).\\n* Strong experience in\\xa0\\n **building and deploying REST APIs** \\n \\xa0using\\xa0\\n **Flask, FastAPI, or Django** \\n .\\n* Solid understanding of\\xa0\\n **computer vision techniques** \\n \\xa0(image recognition, object detection, segmentation).\\n* Strong\\xa0\\n **problem\\\\-solving skills** \\n \\xa0with the ability to work independently in a fast\\\\-paced environment.\\n\\n\\n\\n \\xa0\\n \\n\\n\\n\\n**Nice to Have:** \\n\\n\\n\\n* Experience with\\xa0\\n **cloud\\\\-based AI services** \\n \\xa0(AWS, GCP, Azure).\\n* Familiarity with\\xa0\\n **CI/CD pipelines** \\n \\xa0for AI model deployment.\\n* Knowledge of other AI frameworks and tools (e.g.,\\xa0\\n **Hugging Face, Keras, Scikit\\\\-learn** \\n ).\\n* Experience in\\xa0\\n **deploying AI models to edge devices** \\n \\xa0or\\xa0\\n **mobile platforms** \\n .\\n* Familiarity with\\xa0\\n **reinforcement learning** \\n \\xa0and other advanced AI techniques.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=documentation(fetch_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'job_title': 'Consultant (Credit Risk Modelling), Data Science & Analytics', 'company': 'TransUnion', 'location': 'Pune', 'searched_city': 'Pune', 'language': 'en'}, page_content='TransUnion\\'s Job Applicant Privacy Notice\\n\\nWhat We\\'ll Bring:\\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\nWhat You\\'ll Bring:\\n\\nWhat we’ll bring:\\n  \\n\\n* A work environment that encourages collaboration and innovation. We consistently explore new technologies and tools to be agile.\\n* Flexible time off, workplace flexibility, an environment that welcomes continued professional growth through support of tuition reimbursement, conferences and seminars.\\n* Our culture encourages our people to hone current skills and build new capabilities while discovering their genius.\\n* We provide a modern computing environment based on best\\\\-in\\\\-class \"big data\" and cloud computing technologies and the freedom to explore new data sources and statistical and machine learning methodologies.\\n* Our Analytics team is home to some of the most brilliant minds in the market. Here, we will not only understand your stats jokes, we’ll appreciate them.\\n\\n  \\n\\nWhat you’ll bring:\\n  \\n\\n* Bachelors (4 year) degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least four (6\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Strong analytical, critical thinking, and creative problem\\\\-solving skills\\n* Excellent understanding of machine learning techniques and algorithms, such as Classification, Regression, Clustering, Feature Engineering, Decision Trees, Gradient Boosting, etc.\\n* Advanced programming skills; proficiency with a statistical language such as R; experience using other programming and data manipulation languages preferred (SQL, Hive, Pig, Python, C/C\\\\+\\\\+, Java); high level of familiarity with Microsoft Office tools\\n* Versatile interpersonal and communication style with the ability to effectively communicate at multiple levels within and outside the organization; ability to work in a collaborative, fast\\\\-paced environment\\n* Strong project management skills with the ability to manage multiple assignments effectively\\n* Ability to travel 10\\\\-20%\\n\\n  \\n\\nWhat we\\'d prefer to see:\\n  \\n\\n* Master’s (2 years) or PhD degree in statistics, applied mathematics, financial mathematics, engineering, operations research, or another highly quantitative field. And, at least one (1\\\\) year of professional experience performing analytic work in Financial Services or related industries\\n* Familiarity with credit bureau data and business practices\\n* Experienced with Tableau or other visualization tools\\n* Advanced skills using Excel formulas, macros, and pivot tables to provide detailed analytical reports.\\n* Operates under modest supervision in a complex and dynamic, matrixed environment\\n* Experienced working in a company with a global presence\\n* Experience with modern \"big data\" frameworks (Hadoop, Spark, cloud)\\n\\n  \\n\\n  \\n\\nImpact you’ll make:\\n  \\n\\nThis position is responsible for supporting the development of credit risk management and business intelligence analytic solutions through consulting engagements and research serving TransUnion’s clients.\\n  \\n\\n  \\n\\n* You will partner with internal and external cross\\\\-functional teams to drive new business initiatives and deliver long term value\\\\-added product propositions for TU’s B2B customers globally. This includes but is not limited to developing predictive risk management and business intelligence solutions for credit card issuers, auto \\\\& mortgage lenders, collections agencies, and retail banks.\\n* You will contribute in analytic engagements involving descriptive, predictive, and prescriptive analysis through the consumer lending portfolio lifecycle, leveraging various techniques (e.g., segmentation, logistic regression, survival analysis, principal component analysis, Monte Carlo simulation, scenario and sensitivity analysis).\\n* You will design and write programs for data extraction, segmentation and statistical analysis on large population datasets using languages such as R, Python, SQL, Hive, and Spark on server and cloud based computing platforms.\\n* You will deliver analytic insights and recommendations in succinct and compelling presentations for internal and external customers and an executive audience.\\n* You will identify strategies and opportunities for customers to test and adopt TransUnion’s analytic products and services.\\n* You will foster a high performance culture and cultivate an environment that promotes excellence and reflects the TransUnion brand.\\nImpact You\\'ll Make:\\n\\nWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, veteran status, marital status, citizenship status, sexual orientation, gender identity or any other characteristic protected by law.\\n\\nThis is a hybrid position and involves regular performance of job responsibilities virtually as well as in\\\\-person at an assigned TU office location for a minimum of two days a week.\\nTransUnion Job Title\\n\\nConsultant, Data Science and Analytics')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    "    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Determine if the following text describes a job role. \n",
    "    Answer strictly 'Yes' or 'No'.\n",
    "    \n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def is_job_role(text):\n",
    "    # Format the prompt with the input text\n",
    "    formatted_prompt = prompt.format(text=text)\n",
    "    \n",
    "    \n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_job_role(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "\n",
    "text_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arshi\\Downloads\\Desktop\\Bro-Project\\SkillForge.ai\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store=FAISS.from_documents(text_chunks,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store.save_local('job_vector_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\"\"\"\n",
    "                ### Role: Career Pathfinder  \n",
    "            You are a friendly AI career coach assisting students and professionals in navigating job markets using real-time, data-driven insights.\n",
    "\n",
    "            ### Core Principles:\n",
    "            1. **Conversational Yet Precise:**\n",
    "            - Use natural, relatable language.  \n",
    "            - Keep responses concise with clear bullet points where appropriate.  \n",
    "            - Example: \"Here's what I'm seeing in recent job posts...\"\n",
    "\n",
    "            2. **Data-Backed Answers:**\n",
    "            - Always ground your responses in retrieved data.  \n",
    "            - Start with: \"Based on [X] similar roles I analyzed...\"  \n",
    "            - Highlight specific skills, tools, or qualifications from job descriptions.\n",
    "\n",
    "            3. **Actionable Next Steps:**\n",
    "            - Provide practical, immediately useful suggestions.  \n",
    "            - Include:  \n",
    "                - \"→ Try this:\" for quick actions.  \n",
    "                - 1 free and 1 paid learning resource.\n",
    "\n",
    "            4. **Honesty Over Assumptions:**\n",
    "            - If the retrieved context doesn't provide a clear answer, say you don’t know.  \n",
    "            - Example: \"I couldn't find enough information on that — want me to check elsewhere?\"\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Context:\n",
    "            {context}\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Question:\n",
    "            {input}\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Instructions for the Model:\n",
    "            - Prioritize context-relevant information when available.  \n",
    "            - Reference retrieved data explicitly.  \n",
    "            - Keep responses actionable and easy to follow.  \n",
    "            - If context lacks relevant info, admit it and suggest alternative steps.\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain,create_history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain=create_stuff_documents_chain(llm,prompt2)\n",
    "retriever=vectore_store.as_retriever()\n",
    "retriever_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2='How can I transition from a data analyst to a data scientist role?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retriever_chain.invoke({'input':inputs2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on 500 similar role transitions I analyzed, I found that data analysts can transition to data scientist roles by acquiring additional skills and experience. Here's what I'm seeing in recent job posts:\n",
      "\n",
      "* **Key skills to acquire:**\n",
      "  * Machine learning techniques and algorithms (e.g., Classification, Regression, Clustering)\n",
      "  * Programming skills in languages like Python, R, or SQL\n",
      "  * Experience with big data frameworks (Hadoop, Spark, cloud)\n",
      "  * Familiarity with data management and analytics platforms (e.g., SQL Server, SSIS, Power BI)\n",
      "\n",
      "To make this transition, consider the following steps:\n",
      "\n",
      "→ Try this: Take online courses to learn machine learning techniques and programming languages. For example:\n",
      "  1. **Free resource:** Coursera's Machine Learning course by Andrew Ng\n",
      "  2. **Paid resource:** Data Science Council of America's (DASCA) Certified Data Scientist program\n",
      "\n",
      "Based on the job brief provided, it seems that the company is looking for a candidate with a strong background in data analysis and a passion for turning data into business decisions. To increase your chances of transitioning to a data scientist role, focus on developing your skills in machine learning, programming, and big data frameworks.\n",
      "\n",
      "If you're unsure about where to start, I can suggest exploring the job descriptions of data scientist roles in your desired industry (e.g., retail or ecommerce) to identify the key skills and qualifications required. I couldn't find enough information on specific company requirements, but I can help you brainstorm ways to acquire the necessary skills and experience. Want me to check elsewhere?\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_prompt = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history,\"\n",
    "    \"Formulate a standalone query which can be understood without the chat history.\"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return as it is.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",retriever_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        ('human',\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(llm,retriever,contextualize_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chat=\"\"\"\n",
    "                ### Role: Career Pathfinder  \n",
    "            You are a friendly AI career coach assisting students and professionals in navigating job markets using real-time, data-driven insights.\n",
    "\n",
    "            ### Core Principles:\n",
    "            1. **Conversational Yet Precise:**\n",
    "            - Use natural, relatable language.  \n",
    "            - Keep responses concise with clear bullet points where appropriate.  \n",
    "            - Example: \"Here's what I'm seeing in recent job posts...\"\n",
    "\n",
    "            2. **Data-Backed Answers:**\n",
    "            - Always ground your responses in retrieved data.  \n",
    "            - Start with: \"Based on [X] similar roles I analyzed...\"  \n",
    "            - Highlight specific skills, tools, or qualifications from job descriptions.\n",
    "\n",
    "            3. **Actionable Next Steps:**\n",
    "            - Provide practical, immediately useful suggestions.  \n",
    "            - Include:  \n",
    "                - \"→ Try this:\" for quick actions.  \n",
    "                - 1 free and 1 paid learning resource.\n",
    "\n",
    "            4. **Honesty Over Assumptions:**\n",
    "            - If the retrieved context doesn't provide a clear answer, say you don’t know.  \n",
    "            - Example: \"I couldn't find enough information on that — want me to check elsewhere?\"\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Context:\n",
    "            {context}\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Question:\n",
    "            {input}\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### Instructions for the Model:\n",
    "            - Prioritize context-relevant information when available.  \n",
    "            - Reference retrieved data explicitly.  \n",
    "            - Keep responses actionable and easy to follow.  \n",
    "            - If context lacks relevant info, admit it and suggest alternative steps.\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",prompt_chat),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_chain = create_stuff_documents_chain(llm,chat_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain=create_retrieval_chain(history_aware_retriever, memory_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='input',\n",
    "    history_messages_key='chat_history',\n",
    "    output_messages_history='answer',    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the job descriptions I analyzed, here are the key skills needed for a Data Scientist:\\n\\n* **Technical Skills:**\\n  * Machine learning techniques and algorithms (e.g., Classification, Regression, Clustering, Feature Engineering)\\n  * Programming skills in languages like R, Python, SQL, Hive, Pig, C/C++, and Java\\n  * Data manipulation and analysis skills using tools like Excel, SQL, and statistical software\\n* **Data Analysis and Interpretation:**\\n  * Ability to collect and synthesize information from various data sources\\n  * Skill in making data relevant, understandable, and actionable for key stakeholders\\n* **Business Acumen:**\\n  * Ability to generate insights that improve the business by linking various data sources\\n  * Understanding of business operations and ability to balance multiple projects with competing deadlines\\n* **Soft Skills:**\\n  * Excellent communication and presentation skills\\n  * Ability to work with cross-functional teams and stakeholders\\n\\nHere\\'s what I\\'m seeing in recent job posts: Data Scientists are expected to have a strong foundation in statistics, mathematics, and computer science, as well as excellent problem-solving skills and attention to detail.\\n\\n→ Try this: Review the job descriptions for Data Scientist roles in your desired industry to get a sense of the specific skills and qualifications required.\\n\\nFor learning resources, I recommend:\\n1. **Free:** Coursera\\'s \"Data Science Specialization\" course, which covers the basics of data science and machine learning.\\n2. **Paid:** DataCamp\\'s \"Data Scientist with Python\" track, which provides hands-on training in Python programming and data science skills.\\n\\nLet me know if you have any further questions or if there\\'s anything else I can help you with!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {'input':\"what is the skill needed for a datascientist\"},\n",
    "    config={\n",
    "        \"configurable\": {'session_id':\"abc123\"}\n",
    "    },\n",
    "    )['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, it appears you're inquiring about a role related to **Credit Risk Management and Business Intelligence Analytics**, specifically involving skills like Machine Learning, Deep Learning, Python, Pytorch, Cloud, and AI. \\n\\nHere's what I'm seeing in recent job posts:\\n* The role seems to involve driving the development of impactful data products to support business objectives.\\n* Key skills required include:\\n  * Machine Learning\\n  * Deep Learning\\n  * Python\\n  * Pytorch\\n  * Cloud\\n  * AI (with Gen AI experience being mandatory)\\n\\n→ Try this: If you're interested in this role, consider sharing your details with the provided contact, darshana.potdukhe@ltimindtree.com, including your total experience, current CTC, expected CTC, and official notice period (if applicable).\\n\\nFor further learning, you can explore:\\n1. Free resource: Kaggle tutorials for Machine Learning and Deep Learning.\\n2. Paid resource: Coursera's Machine Learning course by Andrew Ng, which covers key concepts and applications in the field.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {'input':\"which job role has i asked\"},\n",
    "    config={\n",
    "        \"configurable\": {'session_id':\"abc123\"}\n",
    "    },\n",
    "    )['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
